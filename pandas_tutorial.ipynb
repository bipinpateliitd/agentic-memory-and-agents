{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Pandas Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to pandas, covering everything from basics to advanced operations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Pandas](#introduction)\n",
    "2. [Creating DataFrames](#creating-dataframes)\n",
    "3. [Reading and Writing Data](#reading-writing)\n",
    "4. [Data Inspection](#data-inspection)\n",
    "5. [Data Selection and Indexing](#selection-indexing)\n",
    "6. [Data Cleaning](#data-cleaning)\n",
    "7. [Data Manipulation](#data-manipulation)\n",
    "8. [Grouping and Aggregation](#grouping-aggregation)\n",
    "9. [Merging and Joining](#merging-joining)\n",
    "10. [Time Series](#time-series)\n",
    "11. [Advanced Operations](#advanced-operations)\n",
    "12. [Practice Exercises](#practice-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas <a id='introduction'></a>\n",
    "\n",
    "Pandas is a powerful Python library for data manipulation and analysis. It provides two main data structures:\n",
    "- **Series**: 1-dimensional labeled array\n",
    "- **DataFrame**: 2-dimensional labeled data structure (like a table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "NumPy version: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Series\n",
    "s = pd.Series([10, 20, 30, 40, 50])\n",
    "print(\"Simple Series:\")\n",
    "print(s)\n",
    "print(\"\\nSeries with custom index:\")\n",
    "s_indexed = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating DataFrames <a id='creating-dataframes'></a>\n",
    "\n",
    "Let's create comprehensive dummy datasets for our tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create Employee Dataset\n",
    "n_employees = 100\n",
    "\n",
    "employee_data = {\n",
    "    'employee_id': range(1001, 1001 + n_employees),\n",
    "    'name': [f\"Employee_{i}\" for i in range(1, n_employees + 1)],\n",
    "    'department': np.random.choice(['Sales', 'Engineering', 'HR', 'Marketing', 'Finance'], n_employees),\n",
    "    'age': np.random.randint(22, 60, n_employees),\n",
    "    'salary': np.random.randint(40000, 150000, n_employees).astype(float),  # Convert to float to allow NaN\n",
    "    'years_experience': np.random.randint(0, 30, n_employees),\n",
    "    'performance_score': np.random.uniform(2.5, 5.0, n_employees).round(2),\n",
    "    'city': np.random.choice(['New York', 'San Francisco', 'Chicago', 'Boston', 'Seattle'], n_employees),\n",
    "    'hire_date': [datetime(2020, 1, 1) + timedelta(days=int(x)) for x in np.random.randint(0, 1460, n_employees)]\n",
    "}\n",
    "\n",
    "# Add some missing values intentionally\n",
    "employee_data['performance_score'][np.random.choice(n_employees, 10, replace=False)] = np.nan\n",
    "employee_data['salary'][np.random.choice(n_employees, 5, replace=False)] = np.nan\n",
    "\n",
    "df_employees = pd.DataFrame(employee_data)\n",
    "\n",
    "print(\"Employee Dataset created!\")\n",
    "print(f\"Shape: {df_employees.shape}\")\n",
    "df_employees.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sales Dataset\n",
    "n_sales = 500\n",
    "\n",
    "sales_data = {\n",
    "    'sale_id': range(5001, 5001 + n_sales),\n",
    "    'employee_id': np.random.choice(df_employees['employee_id'].values, n_sales),\n",
    "    'product': np.random.choice(['Product_A', 'Product_B', 'Product_C', 'Product_D', 'Product_E'], n_sales),\n",
    "    'quantity': np.random.randint(1, 50, n_sales),\n",
    "    'unit_price': np.random.uniform(10, 500, n_sales).round(2),\n",
    "    'sale_date': [datetime(2023, 1, 1) + timedelta(days=int(x)) for x in np.random.randint(0, 365, n_sales)],\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_sales)\n",
    "}\n",
    "\n",
    "df_sales = pd.DataFrame(sales_data)\n",
    "df_sales['total_amount'] = (df_sales['quantity'] * df_sales['unit_price']).round(2)\n",
    "\n",
    "print(\"Sales Dataset created!\")\n",
    "print(f\"Shape: {df_sales.shape}\")\n",
    "df_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Customer Dataset\n",
    "n_customers = 200\n",
    "\n",
    "customer_data = {\n",
    "    'customer_id': range(2001, 2001 + n_customers),\n",
    "    'customer_name': [f\"Customer_{i}\" for i in range(1, n_customers + 1)],\n",
    "    'email': [f\"customer{i}@email.com\" for i in range(1, n_customers + 1)],\n",
    "    'country': np.random.choice(['USA', 'Canada', 'UK', 'Germany', 'France', 'Japan'], n_customers),\n",
    "    'signup_date': [datetime(2022, 1, 1) + timedelta(days=int(x)) for x in np.random.randint(0, 730, n_customers)],\n",
    "    'total_purchases': np.random.randint(0, 50, n_customers),\n",
    "    'lifetime_value': np.random.uniform(100, 10000, n_customers).round(2)\n",
    "}\n",
    "\n",
    "df_customers = pd.DataFrame(customer_data)\n",
    "\n",
    "print(\"Customer Dataset created!\")\n",
    "print(f\"Shape: {df_customers.shape}\")\n",
    "df_customers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Different Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dictionary\n",
    "df_dict = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df_dict)\n",
    "\n",
    "# From list of lists\n",
    "df_list = pd.DataFrame(\n",
    "    [[1, 4, 7], [2, 5, 8], [3, 6, 9]],\n",
    "    columns=['A', 'B', 'C']\n",
    ")\n",
    "print(\"\\nDataFrame from list of lists:\")\n",
    "print(df_list)\n",
    "\n",
    "# From numpy array\n",
    "df_numpy = pd.DataFrame(\n",
    "    np.random.randn(5, 3),\n",
    "    columns=['X', 'Y', 'Z']\n",
    ")\n",
    "print(\"\\nDataFrame from numpy array:\")\n",
    "print(df_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading and Writing Data <a id='reading-writing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our datasets to CSV files\n",
    "df_employees.to_csv('employees.csv', index=False)\n",
    "df_sales.to_csv('sales.csv', index=False)\n",
    "df_customers.to_csv('customers.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved to CSV files!\")\n",
    "\n",
    "# Read from CSV\n",
    "df_read = pd.read_csv('employees.csv')\n",
    "print(\"\\nDataset read from CSV:\")\n",
    "print(df_read.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel (requires openpyxl)\n",
    "try:\n",
    "    with pd.ExcelWriter('company_data.xlsx') as writer:\n",
    "        df_employees.to_excel(writer, sheet_name='Employees', index=False)\n",
    "        df_sales.to_excel(writer, sheet_name='Sales', index=False)\n",
    "        df_customers.to_excel(writer, sheet_name='Customers', index=False)\n",
    "    print(\"Data saved to Excel file!\")\n",
    "except ImportError:\n",
    "    print(\"openpyxl not installed. Install with: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Inspection <a id='data-inspection'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(df_employees.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset Shape:\", df_employees.shape)\n",
    "print(\"Number of rows:\", len(df_employees))\n",
    "print(\"Number of columns:\", len(df_employees.columns))\n",
    "print(\"Column names:\", df_employees.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df_employees.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df_employees.tail())\n",
    "\n",
    "print(\"\\nRandom 5 rows:\")\n",
    "display(df_employees.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df_employees.describe())\n",
    "\n",
    "print(\"\\nSummary for all columns (including non-numeric):\")\n",
    "display(df_employees.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data types:\")\n",
    "print(df_employees.dtypes)\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(df_employees.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"Missing values count:\")\n",
    "print(df_employees.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values percentage:\")\n",
    "print((df_employees.isnull().sum() / len(df_employees) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts\n",
    "print(\"Department distribution:\")\n",
    "print(df_employees['department'].value_counts())\n",
    "\n",
    "print(\"\\nDepartment distribution (normalized):\")\n",
    "print(df_employees['department'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Selection and Indexing <a id='selection-indexing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns\n",
    "print(\"Single column (Series):\")\n",
    "print(df_employees['name'].head())\n",
    "\n",
    "print(\"\\nMultiple columns (DataFrame):\")\n",
    "print(df_employees[['name', 'department', 'salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows by position (iloc)\n",
    "print(\"First row:\")\n",
    "print(df_employees.iloc[0])\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_employees.iloc[:5])\n",
    "\n",
    "print(\"\\nSpecific rows and columns:\")\n",
    "print(df_employees.iloc[0:5, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows by label (loc)\n",
    "print(\"Selecting by label:\")\n",
    "print(df_employees.loc[0:4, ['name', 'department', 'salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing\n",
    "print(\"Employees in Engineering department:\")\n",
    "engineering = df_employees[df_employees['department'] == 'Engineering']\n",
    "print(engineering.head())\n",
    "\n",
    "print(\"\\nEmployees with salary > 100000:\")\n",
    "high_earners = df_employees[df_employees['salary'] > 100000]\n",
    "print(high_earners.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions\n",
    "print(\"Engineering employees with salary > 80000:\")\n",
    "filtered = df_employees[\n",
    "    (df_employees['department'] == 'Engineering') & \n",
    "    (df_employees['salary'] > 80000)\n",
    "]\n",
    "print(filtered.head())\n",
    "\n",
    "print(\"\\nEmployees in Sales OR Marketing:\")\n",
    "sales_marketing = df_employees[\n",
    "    (df_employees['department'] == 'Sales') | \n",
    "    (df_employees['department'] == 'Marketing')\n",
    "]\n",
    "print(sales_marketing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using isin() for multiple values\n",
    "print(\"Employees in specific departments:\")\n",
    "specific_depts = df_employees[df_employees['department'].isin(['Sales', 'Engineering', 'HR'])]\n",
    "print(specific_depts.head())\n",
    "\n",
    "print(\"\\nEmployees in specific cities:\")\n",
    "specific_cities = df_employees[df_employees['city'].isin(['New York', 'San Francisco'])]\n",
    "print(specific_cities.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Cleaning <a id='data-cleaning'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df_employees.isnull().sum())\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df_employees.copy()\n",
    "\n",
    "# Fill missing performance scores with median\n",
    "df_clean['performance_score'].fillna(df_clean['performance_score'].median(), inplace=True)\n",
    "\n",
    "# Fill missing salaries with mean by department\n",
    "df_clean['salary'] = df_clean.groupby('department')['salary'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values\n",
    "df_dropped = df_employees.dropna()\n",
    "print(f\"Original shape: {df_employees.shape}\")\n",
    "print(f\"After dropping NaN: {df_dropped.shape}\")\n",
    "\n",
    "# Dropping columns with missing values\n",
    "df_dropped_cols = df_employees.dropna(axis=1)\n",
    "print(f\"After dropping columns with NaN: {df_dropped_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "print(f\"Duplicates in employees: {df_employees.duplicated().sum()}\")\n",
    "\n",
    "# Create some duplicates for demonstration\n",
    "df_with_dupes = pd.concat([df_employees, df_employees.head(5)], ignore_index=True)\n",
    "print(f\"\\nDuplicates after adding: {df_with_dupes.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_dupes = df_with_dupes.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_no_dupes.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversion\n",
    "print(\"Original data types:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# Convert hire_date to datetime\n",
    "df_clean['hire_date'] = pd.to_datetime(df_clean['hire_date'])\n",
    "\n",
    "# Convert department to category\n",
    "df_clean['department'] = df_clean['department'].astype('category')\n",
    "\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df_renamed = df_clean.rename(columns={\n",
    "    'employee_id': 'emp_id',\n",
    "    'years_experience': 'experience_years'\n",
    "})\n",
    "print(\"Renamed columns:\")\n",
    "print(df_renamed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations\n",
    "print(\"Original names:\")\n",
    "print(df_clean['name'].head())\n",
    "\n",
    "# Convert to uppercase\n",
    "df_clean['name_upper'] = df_clean['name'].str.upper()\n",
    "print(\"\\nUppercase names:\")\n",
    "print(df_clean['name_upper'].head())\n",
    "\n",
    "# Extract parts of strings\n",
    "df_clean['employee_number'] = df_clean['name'].str.extract(r'(\\d+)')\n",
    "print(\"\\nExtracted employee numbers:\")\n",
    "print(df_clean[['name', 'employee_number']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Manipulation <a id='data-manipulation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns\n",
    "df_clean['salary_per_year_exp'] = (df_clean['salary'] / (df_clean['years_experience'] + 1)).round(2)\n",
    "df_clean['age_group'] = pd.cut(df_clean['age'], bins=[0, 30, 40, 50, 100], labels=['20-30', '31-40', '41-50', '50+'])\n",
    "\n",
    "print(\"New columns added:\")\n",
    "print(df_clean[['name', 'age', 'age_group', 'salary', 'years_experience', 'salary_per_year_exp']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "def categorize_performance(score):\n",
    "    if pd.isna(score):\n",
    "        return 'Unknown'\n",
    "    elif score >= 4.5:\n",
    "        return 'Excellent'\n",
    "    elif score >= 3.5:\n",
    "        return 'Good'\n",
    "    elif score >= 2.5:\n",
    "        return 'Average'\n",
    "    else:\n",
    "        return 'Below Average'\n",
    "\n",
    "df_clean['performance_category'] = df_clean['performance_score'].apply(categorize_performance)\n",
    "\n",
    "print(\"Performance categories:\")\n",
    "print(df_clean[['name', 'performance_score', 'performance_category']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting\n",
    "print(\"Top 10 highest paid employees:\")\n",
    "print(df_clean.nlargest(10, 'salary')[['name', 'department', 'salary']])\n",
    "\n",
    "print(\"\\nBottom 10 lowest paid employees:\")\n",
    "print(df_clean.nsmallest(10, 'salary')[['name', 'department', 'salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by multiple columns\n",
    "print(\"Sorted by department and salary:\")\n",
    "sorted_df = df_clean.sort_values(['department', 'salary'], ascending=[True, False])\n",
    "print(sorted_df[['name', 'department', 'salary']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking\n",
    "df_clean['salary_rank'] = df_clean['salary'].rank(ascending=False, method='min')\n",
    "df_clean['dept_salary_rank'] = df_clean.groupby('department')['salary'].rank(ascending=False, method='min')\n",
    "\n",
    "print(\"Salary rankings:\")\n",
    "print(df_clean[['name', 'department', 'salary', 'salary_rank', 'dept_salary_rank']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Grouping and Aggregation <a id='grouping-aggregation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple groupby\n",
    "print(\"Average salary by department:\")\n",
    "dept_avg_salary = df_clean.groupby('department')['salary'].mean().round(2)\n",
    "print(dept_avg_salary)\n",
    "\n",
    "print(\"\\nEmployee count by department:\")\n",
    "dept_count = df_clean.groupby('department').size()\n",
    "print(dept_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregations\n",
    "print(\"Salary statistics by department:\")\n",
    "dept_stats = df_clean.groupby('department')['salary'].agg([\n",
    "    'count', 'mean', 'median', 'min', 'max', 'std'\n",
    "]).round(2)\n",
    "print(dept_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating multiple columns\n",
    "print(\"Multiple column aggregations:\")\n",
    "multi_agg = df_clean.groupby('department').agg({\n",
    "    'salary': ['mean', 'max'],\n",
    "    'age': ['mean', 'min', 'max'],\n",
    "    'years_experience': 'mean',\n",
    "    'performance_score': 'mean'\n",
    "}).round(2)\n",
    "print(multi_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation functions\n",
    "def salary_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "print(\"Custom aggregations:\")\n",
    "custom_agg = df_clean.groupby('department')['salary'].agg([\n",
    "    ('avg_salary', 'mean'),\n",
    "    ('salary_range', salary_range),\n",
    "    ('total_payroll', 'sum')\n",
    "]).round(2)\n",
    "print(custom_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby multiple columns\n",
    "print(\"Groupby department and city:\")\n",
    "dept_city_stats = df_clean.groupby(['department', 'city']).agg({\n",
    "    'salary': 'mean',\n",
    "    'employee_id': 'count'\n",
    "}).round(2)\n",
    "dept_city_stats.columns = ['avg_salary', 'employee_count']\n",
    "print(dept_city_stats.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tables\n",
    "print(\"Pivot table - Average salary by department and city:\")\n",
    "pivot = pd.pivot_table(\n",
    "    df_clean,\n",
    "    values='salary',\n",
    "    index='department',\n",
    "    columns='city',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0\n",
    ").round(2)\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation\n",
    "print(\"Cross-tabulation - Department vs City:\")\n",
    "crosstab = pd.crosstab(\n",
    "    df_clean['department'],\n",
    "    df_clean['city'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Merging and Joining <a id='merging-joining'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "print(\"Inner join - Employees and Sales:\")\n",
    "inner_merged = pd.merge(\n",
    "    df_employees[['employee_id', 'name', 'department']],\n",
    "    df_sales[['sale_id', 'employee_id', 'product', 'total_amount']],\n",
    "    on='employee_id',\n",
    "    how='inner'\n",
    ")\n",
    "print(inner_merged.head(10))\n",
    "print(f\"\\nShape: {inner_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "print(\"Left join - All employees with their sales:\")\n",
    "left_merged = pd.merge(\n",
    "    df_employees[['employee_id', 'name', 'department']],\n",
    "    df_sales.groupby('employee_id').agg({\n",
    "        'sale_id': 'count',\n",
    "        'total_amount': 'sum'\n",
    "    }).reset_index(),\n",
    "    on='employee_id',\n",
    "    how='left'\n",
    ")\n",
    "left_merged.columns = ['employee_id', 'name', 'department', 'num_sales', 'total_sales']\n",
    "left_merged.fillna(0, inplace=True)\n",
    "print(left_merged.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating DataFrames\n",
    "print(\"Concatenating vertically (rows):\")\n",
    "df1 = df_employees.head(5)\n",
    "df2 = df_employees.tail(5)\n",
    "concat_vertical = pd.concat([df1, df2], ignore_index=True)\n",
    "print(concat_vertical[['employee_id', 'name', 'department']])\n",
    "\n",
    "print(\"\\nConcatenating horizontally (columns):\")\n",
    "df_extra = pd.DataFrame({\n",
    "    'bonus': np.random.randint(1000, 10000, 5)\n",
    "})\n",
    "concat_horizontal = pd.concat([df1[['name', 'salary']].reset_index(drop=True), df_extra], axis=1)\n",
    "print(concat_horizontal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Time Series <a id='time-series'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with dates\n",
    "df_sales['sale_date'] = pd.to_datetime(df_sales['sale_date'])\n",
    "\n",
    "# Extract date components\n",
    "df_sales['year'] = df_sales['sale_date'].dt.year\n",
    "df_sales['month'] = df_sales['sale_date'].dt.month\n",
    "df_sales['day'] = df_sales['sale_date'].dt.day\n",
    "df_sales['day_of_week'] = df_sales['sale_date'].dt.day_name()\n",
    "df_sales['quarter'] = df_sales['sale_date'].dt.quarter\n",
    "\n",
    "print(\"Date components:\")\n",
    "print(df_sales[['sale_date', 'year', 'month', 'day', 'day_of_week', 'quarter']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based grouping\n",
    "print(\"Monthly sales:\")\n",
    "monthly_sales = df_sales.groupby(df_sales['sale_date'].dt.to_period('M')).agg({\n",
    "    'total_amount': 'sum',\n",
    "    'sale_id': 'count'\n",
    "}).round(2)\n",
    "monthly_sales.columns = ['total_revenue', 'num_sales']\n",
    "print(monthly_sales.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling (set date as index first)\n",
    "df_sales_indexed = df_sales.set_index('sale_date').sort_index()\n",
    "\n",
    "print(\"Weekly sales (resampled):\")\n",
    "weekly_sales = df_sales_indexed['total_amount'].resample('W').sum().round(2)\n",
    "print(weekly_sales.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling windows\n",
    "print(\"7-day rolling average of sales:\")\n",
    "daily_sales = df_sales_indexed['total_amount'].resample('D').sum()\n",
    "rolling_avg = daily_sales.rolling(window=7).mean().round(2)\n",
    "print(rolling_avg.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date filtering\n",
    "print(\"Sales in Q1 2023:\")\n",
    "q1_sales = df_sales[\n",
    "    (df_sales['sale_date'] >= '2023-01-01') & \n",
    "    (df_sales['sale_date'] <= '2023-03-31')\n",
    "]\n",
    "print(f\"Total Q1 sales: ${q1_sales['total_amount'].sum():,.2f}\")\n",
    "print(f\"Number of transactions: {len(q1_sales)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Operations <a id='advanced-operations'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window functions\n",
    "print(\"Cumulative sum of sales by employee:\")\n",
    "df_sales_sorted = df_sales.sort_values(['employee_id', 'sale_date'])\n",
    "df_sales_sorted['cumulative_sales'] = df_sales_sorted.groupby('employee_id')['total_amount'].cumsum()\n",
    "print(df_sales_sorted[['employee_id', 'sale_date', 'total_amount', 'cumulative_sales']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift and lag\n",
    "print(\"Previous sale amount (lag):\")\n",
    "df_sales_sorted['prev_sale'] = df_sales_sorted.groupby('employee_id')['total_amount'].shift(1)\n",
    "df_sales_sorted['sale_change'] = df_sales_sorted['total_amount'] - df_sales_sorted['prev_sale']\n",
    "print(df_sales_sorted[['employee_id', 'total_amount', 'prev_sale', 'sale_change']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning and discretization\n",
    "print(\"Salary bins:\")\n",
    "df_clean['salary_bin'] = pd.cut(\n",
    "    df_clean['salary'],\n",
    "    bins=[0, 50000, 75000, 100000, 150000],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "print(df_clean['salary_bin'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nQuantile-based bins:\")\n",
    "df_clean['salary_quantile'] = pd.qcut(\n",
    "    df_clean['salary'],\n",
    "    q=4,\n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    ")\n",
    "print(df_clean['salary_quantile'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt and pivot\n",
    "print(\"Original wide format:\")\n",
    "wide_df = df_clean.groupby('department')[['salary', 'age', 'years_experience']].mean().round(2)\n",
    "print(wide_df)\n",
    "\n",
    "print(\"\\nMelted to long format:\")\n",
    "long_df = wide_df.reset_index().melt(\n",
    "    id_vars='department',\n",
    "    var_name='metric',\n",
    "    value_name='value'\n",
    ")\n",
    "print(long_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query method\n",
    "print(\"Using query method:\")\n",
    "result = df_clean.query('department == \"Engineering\" and salary > 80000 and age < 40')\n",
    "print(result[['name', 'department', 'age', 'salary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "print(\"Correlation matrix:\")\n",
    "numeric_cols = ['age', 'salary', 'years_experience', 'performance_score']\n",
    "correlation = df_clean[numeric_cols].corr().round(3)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding lists\n",
    "print(\"Exploding lists:\")\n",
    "df_with_lists = pd.DataFrame({\n",
    "    'employee': ['Alice', 'Bob', 'Charlie'],\n",
    "    'skills': [['Python', 'SQL'], ['Java', 'C++', 'Python'], ['R', 'SQL', 'Excel']]\n",
    "})\n",
    "print(\"Before explode:\")\n",
    "print(df_with_lists)\n",
    "\n",
    "df_exploded = df_with_lists.explode('skills')\n",
    "print(\"\\nAfter explode:\")\n",
    "print(df_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Practice Exercises <a id='practice-exercises'></a>\n",
    "\n",
    "Try these exercises to test your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic Analysis\n",
    "Find the top 5 departments by average salary and show the employee count for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Filtering\n",
    "Find all employees who:\n",
    "- Are in the Engineering or Sales department\n",
    "- Have more than 5 years of experience\n",
    "- Have a performance score above 4.0\n",
    "- Earn more than the median salary of their department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Sales Analysis\n",
    "Calculate the total sales revenue by product and region, and find which product-region combination has the highest revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Time Series Analysis\n",
    "Calculate the month-over-month growth rate of sales revenue for 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Advanced Grouping\n",
    "For each department, find:\n",
    "- The employee with the highest salary\n",
    "- The employee with the most years of experience\n",
    "- The average performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions to Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "print(\"Solution 1: Top 5 departments by average salary\")\n",
    "dept_analysis = df_clean.groupby('department').agg({\n",
    "    'salary': 'mean',\n",
    "    'employee_id': 'count'\n",
    "}).round(2)\n",
    "dept_analysis.columns = ['avg_salary', 'employee_count']\n",
    "print(dept_analysis.nlargest(5, 'avg_salary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "print(\"Solution 2: Filtered employees\")\n",
    "dept_median_salary = df_clean.groupby('department')['salary'].transform('median')\n",
    "filtered_employees = df_clean[\n",
    "    (df_clean['department'].isin(['Engineering', 'Sales'])) &\n",
    "    (df_clean['years_experience'] > 5) &\n",
    "    (df_clean['performance_score'] > 4.0) &\n",
    "    (df_clean['salary'] > dept_median_salary)\n",
    "]\n",
    "print(filtered_employees[['name', 'department', 'years_experience', 'performance_score', 'salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3\n",
    "print(\"Solution 3: Sales revenue by product and region\")\n",
    "product_region_sales = df_sales.groupby(['product', 'region'])['total_amount'].sum().round(2)\n",
    "print(product_region_sales.sort_values(ascending=False).head(10))\n",
    "print(f\"\\nHighest revenue combination: {product_region_sales.idxmax()} with ${product_region_sales.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 4\n",
    "print(\"Solution 4: Month-over-month growth rate\")\n",
    "monthly_revenue = df_sales.groupby(df_sales['sale_date'].dt.to_period('M'))['total_amount'].sum()\n",
    "mom_growth = monthly_revenue.pct_change() * 100\n",
    "print(mom_growth.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 5\n",
    "print(\"Solution 5: Department analysis\")\n",
    "\n",
    "# Highest salary employee per department\n",
    "highest_salary = df_clean.loc[df_clean.groupby('department')['salary'].idxmax()]\n",
    "print(\"Highest salary per department:\")\n",
    "print(highest_salary[['department', 'name', 'salary']])\n",
    "\n",
    "# Most experienced employee per department\n",
    "most_experienced = df_clean.loc[df_clean.groupby('department')['years_experience'].idxmax()]\n",
    "print(\"\\nMost experienced per department:\")\n",
    "print(most_experienced[['department', 'name', 'years_experience']])\n",
    "\n",
    "# Average performance score\n",
    "avg_performance = df_clean.groupby('department')['performance_score'].mean().round(2)\n",
    "print(\"\\nAverage performance score per department:\")\n",
    "print(avg_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "1. ✅ Creating and inspecting DataFrames\n",
    "2. ✅ Reading and writing data\n",
    "3. ✅ Data selection and indexing\n",
    "4. ✅ Data cleaning and preprocessing\n",
    "5. ✅ Data manipulation and transformation\n",
    "6. ✅ Grouping and aggregation\n",
    "7. ✅ Merging and joining datasets\n",
    "8. ✅ Time series operations\n",
    "9. ✅ Advanced pandas operations\n",
    "10. ✅ Practice exercises with solutions\n",
    "\n",
    "### Next Steps\n",
    "- Explore visualization with matplotlib and seaborn\n",
    "- Learn about pandas performance optimization\n",
    "- Practice with real-world datasets\n",
    "- Explore pandas integration with SQL databases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
