{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4e2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/bot/learning/.env\")\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25244ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf57e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13231635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304b80ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "simple_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],  # No tools for now, just conversation\n",
    "    system_prompt=\"You are a helpful assistant. Answer questions concisely.\"\n",
    ")\n",
    "\n",
    "print(\"Simple agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0da381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf3d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638b6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4f438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a00f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = simple_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bipin.\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72068688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bipin.', additional_kwargs={}, response_metadata={}, id='65be5ff8-690c-42ba-8586-a9bbb09a6e58'),\n",
       "  AIMessage(content='Nice to meet you, Bipin! How can I help today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 279, 'prompt_tokens': 30, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxwBgcDJcnPNXhGm6d96AX8tWnc1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f43-6ffa-7f52-b3b4-9a06ad57bcd4-0', usage_metadata={'input_tokens': 30, 'output_tokens': 279, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c8a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Bipin! How can I help today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fcec30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b7d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = simple_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfe74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t know your name. What would you like me to call you? Tell me your name and I’ll use it in this chat.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcf2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444ecba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777cfda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5b8f7f",
   "metadata": {},
   "source": [
    "## The Problem - No Memory!\n",
    "\n",
    "### What Just Happened?\n",
    "\n",
    "You probably noticed the chatbot **doesn't remember your name**! This is because:\n",
    "\n",
    "1. Each `invoke()` call is independent\n",
    "2. We only sent the current message, not the conversation history\n",
    "3. The agent has no way to remember previous interactions\n",
    "\n",
    "### Why This Is a Problem\n",
    "\n",
    "- Users expect chatbots to remember context\n",
    "- Real conversations build on previous messages\n",
    "- Without memory, the chatbot feels robotic and unhelpful\n",
    "\n",
    "### The Solution: Short-Term Memory\n",
    "\n",
    "We need to:\n",
    "1. Store conversation history\n",
    "2. Send the full history with each new message\n",
    "3. Use a \"checkpointer\" to persist the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c16f08",
   "metadata": {},
   "source": [
    "# Part2  Adding short term memeory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a343e",
   "metadata": {},
   "source": [
    "### Step 1: Import Memory Components\n",
    "\n",
    "* MemorySaver stores conversation history in memory\n",
    "* For production, you'd use a database checkpointer (SQLite, Postgres, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661a611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16b63691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent with memory created!\n"
     ]
    }
   ],
   "source": [
    "# Create a checkpointer to store conversation history\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Create an agent WITH memory\n",
    "agent_with_memory = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    system_prompt=\"You are a helpful assistant. Remember details from our conversation.\",\n",
    "    checkpointer=memory  # This enables memory!\n",
    ")\n",
    "\n",
    "print(\"Agent with memory created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ecaa3a",
   "metadata": {},
   "source": [
    "### Step 3: Understanding Thread IDs\n",
    "\n",
    "To maintain separate conversations, we use **thread IDs**. Think of a thread as a conversation session.\n",
    "\n",
    "- Each thread has its own memory\n",
    "- Same thread ID = same conversation\n",
    "- Different thread ID = new conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1bc50b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Bipin! I’ll remember your name in this chat. How can I help you today? \\nWould you like to chat, learn something, get help with a task, plan something, or practice a skill? Tell me what you’re interested in or any problem you’re working on.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration with thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
    "\n",
    "# First message in the conversation\n",
    "response1 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bipin.\"}]},\n",
    "    config  # Pass the config to maintain thread\n",
    ")\n",
    "response1[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690c14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605de98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326354bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd4eead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Your name is Bipin. Nice to meet you again, Bipin! What would you like help with today?\n"
     ]
    }
   ],
   "source": [
    "# Second message - the bot should remember the name now!\n",
    "response2 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config  # Same config = same conversation thread\n",
    ")\n",
    "\n",
    "print(\"Bot:\", response2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f229dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cacb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4894fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb5de4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to hear that, Bipin! Chicken with butter is a delicious combo. Want a quick recipe or just some ideas? Here are three easy options:\\n\\n1) Garlic Butter Chicken Skillet (about 20 minutes)\\n- Ingredients: chicken breasts or thighs, salt, pepper, 2–3 tbsp olive oil, 3–4 tbsp butter, 3 cloves garlic, 1/2 cup chicken broth or wine, chopped parsley.\\n- Steps: Season chicken and sear in oil until browned. Remove. In the same pan, melt butter, sauté garlic until fragrant, add broth to deglaze, simmer a couple minutes. Return chicken, cook through, finish with parsley.\\n\\n2) Lemon Butter Chicken (about 25 minutes)\\n- Ingredients: chicken thighs, salt, pepper, 2–3 tbsp butter, 2 cloves garlic, 1/2 cup chicken broth, juice of 1 lemon, thyme.\\n- Steps: Sear chicken until golden. Remove. In same pan, melt butter, sauté garlic, add broth and lemon juice, simmer a few minutes, return chicken, cook until done, finish with thyme.\\n\\n3) Creamy Butter Chicken (Murgh Makhani) — a bit more involved\\n- A flavorful curry-style dish: marinate chicken in yogurt and spices, cook in a tomato-cream-butter sauce, finish with a splash of cream and more butter.\\n\\nIf you tell me what you have on hand, how long you want to cook, or your spice level, I’ll tailor a simple recipe for you. Would you like me to fetch a specific recipe or give you a quick shopping list?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a longer conversation to test memory\n",
    "response3 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I like chicken and Butter\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "response3[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97fd5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to hear that, Bipin! Chicken with butter is a delicious combo. Want a quick recipe or just some ideas? Here are three easy options:\n",
      "\n",
      "1) Garlic Butter Chicken Skillet (about 20 minutes)\n",
      "- Ingredients: chicken breasts or thighs, salt, pepper, 2–3 tbsp olive oil, 3–4 tbsp butter, 3 cloves garlic, 1/2 cup chicken broth or wine, chopped parsley.\n",
      "- Steps: Season chicken and sear in oil until browned. Remove. In the same pan, melt butter, sauté garlic until fragrant, add broth to deglaze, simmer a couple minutes. Return chicken, cook through, finish with parsley.\n",
      "\n",
      "2) Lemon Butter Chicken (about 25 minutes)\n",
      "- Ingredients: chicken thighs, salt, pepper, 2–3 tbsp butter, 2 cloves garlic, 1/2 cup chicken broth, juice of 1 lemon, thyme.\n",
      "- Steps: Sear chicken until golden. Remove. In same pan, melt butter, sauté garlic, add broth and lemon juice, simmer a few minutes, return chicken, cook until done, finish with thyme.\n",
      "\n",
      "3) Creamy Butter Chicken (Murgh Makhani) — a bit more involved\n",
      "- A flavorful curry-style dish: marinate chicken in yogurt and spices, cook in a tomato-cream-butter sauce, finish with a splash of cream and more butter.\n",
      "\n",
      "If you tell me what you have on hand, how long you want to cook, or your spice level, I’ll tailor a simple recipe for you. Would you like me to fetch a specific recipe or give you a quick shopping list?\n"
     ]
    }
   ],
   "source": [
    "print(response3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4eb17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0904f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: From our chat, you like chicken and butter. So buttery, flavorful chicken dishes are right up your alley, especially quick-to-make ones.\n",
      "\n",
      "Would you like me to tailor a recipe or a short menu around those prefs? Tell me your available time, ingredients on hand, and how spicy or creamy you like it, and I’ll customize.\n"
     ]
    }
   ],
   "source": [
    "response4 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What do I like?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Bot:\", response4[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5544269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521eee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response4['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65c030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Full Conversation History ===\")\n",
    "for i, msg in enumerate(response4[\"messages\"], 1):\n",
    "    role = msg.__class__.__name__.replace(\"Message\", \"\")\n",
    "    content = msg.content\n",
    "    print(f\"{i}. [{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c3efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a677be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6202f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd040fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = {\"configurable\": {\"thread_id\": \"conversation_2\"}}\n",
    "\n",
    "response_new = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    new_config\n",
    ")\n",
    "\n",
    "print(\"Bot (new conversation):\", response_new[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot():\n",
    "\n",
    "    \n",
    "    # Create a new conversation thread\n",
    "    thread_config = {\"configurable\": {\"thread_id\": \"session 1\"}}\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_message = input(\"You: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if user_message.lower() in ['quit', 'exit', 'bye']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Send message to agent\n",
    "        response = agent_with_memory.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": user_message}]},\n",
    "            thread_config\n",
    "        )\n",
    "        \n",
    "        # Print bot response\n",
    "        print(f\"Bot: {response['messages'][-1].content}\\n\")\n",
    "# chat_with_bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce078c",
   "metadata": {},
   "source": [
    "###  The Memory Problem\n",
    "- Without memory, chatbots can't maintain context\n",
    "- Each conversation starts from scratch\n",
    "- Poor user experience\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **create_agent()** - The standard way to build agents in LangChain\n",
    "2. **Checkpointer** - Saves conversation state (MemorySaver, SQLite, Postgres)\n",
    "3. **Thread ID** - Identifies a conversation session\n",
    "4. **Short-term memory** - Remembers within a conversation thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e755bb",
   "metadata": {},
   "source": [
    "\n",
    "### Behind the Scenes\n",
    "\n",
    "When you use a checkpointer:\n",
    "\n",
    "1. **First message**: Agent processes it and saves the state\n",
    "2. **Second message**: Agent loads previous state, adds new message, processes, saves updated state\n",
    "3. **Continue**: This repeats for every message\n",
    "\n",
    "### Message Types\n",
    "\n",
    "- **HumanMessage**: Messages from the user\n",
    "- **AIMessage**: Messages from the assistant\n",
    "- **SystemMessage**: Instructions for the agent (system prompt)\n",
    "- **ToolMessage**: Results from tool executions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe081bbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cfaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037ffba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d17b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4254f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94206c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66eb5323",
   "metadata": {},
   "source": [
    "### The Cost Problem\n",
    "\n",
    "As conversations grow longer (e.g., 20+ questions), the context window grows with every message. This leads to:\n",
    "\n",
    "- **Higher API costs**: You're charged for every token in the conversation history\n",
    "- **Slower responses**: More tokens = more processing time\n",
    "- **Context window limits**: Eventually, you'll hit the model's maximum token limit\n",
    "\n",
    "### The Solution: Two Intelligent Approaches\n",
    "\n",
    "1. **Message Trimming**: Keep only recent messages (fast but loses context)\n",
    "2. **Message Summarization**: Compress old messages into a summary (preserves context, slightly more cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0394d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f574b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdee4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4cad12",
   "metadata": {},
   "source": [
    "\n",
    "## Approach 1: Message Trimming with Middleware\n",
    "\n",
    "The simplest approach: automatically keep only the last N messages. LangChain provides middleware that runs **before** the model is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31e1d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trim middleware function created!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules for message trimming\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "# Define a middleware function that trims messages\n",
    "@before_model\n",
    "def trim_messages_middleware(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Keep only the last few messages to fit context window.\n",
    "    This runs BEFORE each model call.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If we have 5 or fewer messages, no need to trim\n",
    "    if len(messages) <= 5:\n",
    "        return None  # No changes needed\n",
    "    \n",
    "    # Keep the first message (usually system/initial context)\n",
    "    first_msg = messages[0]\n",
    "    \n",
    "    # Keep the last 4 messages (2 turns of conversation)\n",
    "    recent_messages = messages[-4:]\n",
    "    \n",
    "    # Create new message list\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "    \n",
    "    # Return the trimmed messages\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),  # Remove all existing messages\n",
    "            *new_messages  # Add back only the messages we want to keep\n",
    "        ]\n",
    "    }\n",
    "\n",
    "print(\"Trim middleware function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59efd83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent with message trimming created!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "trim_memory = MemorySaver()\n",
    "\n",
    "agent_with_trimming = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages_middleware],  # Add our trimming middleware\n",
    "    checkpointer=trim_memory\n",
    ")\n",
    "\n",
    "print(\"Agent with message trimming created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5734cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc953924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0dfbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc7c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending messages to agent with trimming...\n",
      "\n",
      "1. You: Hi! My name is Bipin.\n",
      "   Bot: Hi Bipin! Nice to meet you. How can I help today? I can answer questions, explain concepts, help with writing or coding, plan things, practice problems, or brainstorm ideas. Tell me a bit about what you’d like to do or the goal you have in mind.\n",
      "   Messages in history: 2\n",
      "\n",
      "2. You: I live in Mumbai.\n",
      "   Bot: Nice to meet you, Bipin! Since you’re in Mumbai, I can tailor tips and info to your city. What would you like to do today? Here are a few quick ideas:\n",
      "\n",
      "- Plan a weekend in Mumbai: top places to visit and easy routes to beat traffic\n",
      "- Weather updates and monsoon tips\n",
      "- Quick Marathi or Hindi phrases for daily use\n",
      "- Food and dining ideas by neighborhood\n",
      "- Help with coding, math, or exam/practice problems\n",
      "- Local tips for living or commuting in the city\n",
      "\n",
      "Tell me what you’re aiming for, and I’ll tailor the help.\n",
      "   Messages in history: 4\n",
      "\n",
      "3. You: I work as a software engineer.\n",
      "   Bot: Nice to know, Bipin. Since you’re in Mumbai and work as a software engineer, I can tailor help to your career and locally relevant needs. Here are some good next steps you can pick from (or mix):\n",
      "\n",
      "- Interview prep (DSA and System Design): structured practice for on-site/offshore roles, with a plan and mock interviews.\n",
      "- Technical upskilling: pick your stack (e.g., Java/Spring, Python, JavaScript/TypeScript, Go) and target topics like concurrency, async, databases, microservices, and cloud.\n",
      "- DevOps and cloud basics: Docker, Kubernetes, CI/CD pipelines, and cloud (AWS/GCP/Azure) fundamentals.\n",
      "- Code practice plan: weekly schedule with problems from LeetCode/CodeSignal/HackerRank and review routines.\n",
      "- System design and architecture: practice common patterns (caching, data modeling, messaging, event-driven, scalability) with real-world scenarios.\n",
      "- Resume/LinkedIn/Portfolio polish: optimize your resume, highlight Mumbai-specific experience, and showcase side projects or open-source work.\n",
      "- Local networking and learning: I can help you find relevant Mumbai tech meetups, groups, and events (e.g., JS/Java/ML/DevOps communities).\n",
      "\n",
      "To tailor things precisely, could you share:\n",
      "- Which stack you work with and any you want to learn next?\n",
      "- Your goal (e.g., land a new role, get promoted, prepare for interviews, upskill for current projects)?\n",
      "- How many hours per week you can dedicate?\n",
      "\n",
      "If you like, I can also draft a concrete 4-week plan right away based on your answers.\n",
      "   Messages in history: 6\n",
      "\n",
      "4. You: I love playing cricket.\n",
      "   Bot: Nice! Cricket is a fantastic way to unwind and stay fit, especially in Mumbai.\n",
      "\n",
      "Here are a few ways I can help right away. Pick one or mix-and-match:\n",
      "\n",
      "- Skill boost plan (pick batting, bowling, or fielding)\n",
      "  - Batting: warm-up 10 min, shadow swings, 20–30 balls at nets, footwork drills, quick tips for shot selection.\n",
      "  - Bowling: run-up drills, target lines, 20–30 balls at precise lengths, variations (inswing/out-swing).\n",
      "  - Fielding: catching practice, ground fielding, quick retreats and returns, throwing accuracy.\n",
      "- Cricket fitness plan\n",
      "  - 3 sessions/week focusing on endurance, agility, and mobility with cricket-specific drills.\n",
      "- Flexible practice schedule for work\n",
      "  - 3 focused sessions per week (evenings) plus a weekend net or mini-match.\n",
      "- Local playing opportunities in Mumbai\n",
      "  - I can help you find clubs, weekend nets, or MCA/league options near you—tell me your area and preferred format.\n",
      "- Gear and season tips\n",
      "  - Quick gear checklist, monsoon/pitch tips, and safe practice ideas for rainy days.\n",
      "\n",
      "If you’d like, I can draft a concrete 4-week cricket improvement plan. To tailor it, tell me:\n",
      "- Your current level (beginner/intermediate/advanced) and primary focus (batting, bowling, or fielding)\n",
      "- Which format you enjoy (T20, 50-over, or just social nets)\n",
      "- How many hours per week you can dedicate\n",
      "- Your area in Mumbai (so I can suggest nearer clubs or nets)\n",
      "\n",
      "Want me to draft a 4-week plan now? If yes, share the above details and your preferred focus.\n",
      "   Messages in history: 6\n",
      "\n",
      "5. You: My favorite food is biryani.\n",
      "   Bot: Nice pick, Bipin! Biryani is a great comfort meal and fuel for long coding days or cricket sessions. Want me to:\n",
      "\n",
      "- Share a quick, foolproof chicken biryani recipe you can cook at home (30–40 minutes)?\n",
      "- Or give you a list of good Mumbai biryani spots near you?\n",
      "- Or share nutrition tips to pair biryani with cricket training?\n",
      "\n",
      "If you’d like the home recipe, here’s a simple one-pot chicken biryani (serves 4):\n",
      "\n",
      "Ingredients\n",
      "- 500 g chicken, cut into pieces\n",
      "- 2 cups basmati rice, rinsed and soaked 15–20 min\n",
      "- 1 large onion, thinly sliced\n",
      "- 2 tbsp ginger-garlic paste\n",
      "- 1/2 cup yogurt\n",
      "- 1/2 tsp turmeric\n",
      "- 1–2 tsp red chili powder (adjust)\n",
      "- 1 1/2 tsp garam masala\n",
      "- Whole spices: 2 bay leaves, 4-5 cloves, 4 cardamom, 1 cinnamon stick\n",
      "- Salt to taste\n",
      "- 2–3 tbsp oil or ghee\n",
      "- Optional: a pinch saffron in 3 tbsp warm milk, chopped cilantro and mint for layering\n",
      "- Water as needed\n",
      "\n",
      "Steps\n",
      "1) Marinate chicken with yogurt, turmeric, chili powder, garam masala, and salt for 20–30 minutes.\n",
      "2) Parboil rice: bring a pot of water with a pinch of salt and the whole spices to a boil. Cook rice until 70–75% done, then drain.\n",
      "3) In a large pot, fry onions in oil/ghee until deep golden. Remove about half for garnish.\n",
      "4) In the same pot, add marinated chicken. Cook 5–7 minutes until lightly browned; add ginger-garlic paste and a splash of water if needed. Cook until chicken is nearly done.\n",
      "5) Layer: top with the remaining fried onions, cilantro, and mint. Spread the parboiled rice over the chicken. Drizzle saffron milk if using.\n",
      "6) Seal the pot (or cover tightly) and cook on very low heat for 8–12 minutes (dum). Alternatively bake at 180°C for 15 minutes.\n",
      "7) Gently fluff and serve with raita or a simple salad.\n",
      "\n",
      "Variations\n",
      "- Veg version: replace chicken with mixed vegetables or paneer.\n",
      "- Quick version: skip marination and use pre-made biryani spice mix.\n",
      "\n",
      "If you’d rather, tell me your area in Mumbai and I’ll pull together a few good biryani spots nearby. Also, if you’re training, I can share quick nutrition tips to balance biryani with your workouts. Do you prefer home cooking, or a ready-made biryani from a restaurant?\n",
      "   Messages in history: 6\n",
      "\n",
      "6. You: I have a dog named Max.\n",
      "   Bot: Nice! Max sounds like a champ. Here are a few ways I can help with Max and your cricket routine:\n",
      "\n",
      "- Quick dog-care checklist\n",
      "  - Vaccinations, microchip, flea/tick prevention, regular grooming\n",
      "  - Feeding amounts by weight, water hygiene, and a simple weekly weight check\n",
      "  - Safe chew toys and crate/space for downtime\n",
      "\n",
      "- Training and enrichment for Max\n",
      "  - Basic commands: sit, stay, recall, leash manners\n",
      "  - Fun activities: fetch, scent games, short agility-style drills in a park or backyard\n",
      "  - 5–10 minute mini-sessions you can slot between nets or practice days\n",
      "\n",
      "- Fitness-friendly ideas for you both\n",
      "  - Short warm-ups with Max before or after cricket practice (e.g., a brisk 5-minute walk, a few quick sprints with a leash, some recall work)\n",
      "  - Gentle play sessions to burn energy on rest days (tug, fetch, puzzle toys)\n",
      "\n",
      "- Local spot help in Mumbai\n",
      "  - I can find dog-friendly parks, walking routes, and dog-friendly constellations near you—tell me your area and preferred activities.\n",
      "\n",
      "If you’d like, I can tailor a simple 2–4 week plan for Max (training goals, weekly schedule, and quick at-home drills). A few quick details will help:\n",
      "- Max’s age, breed (if you know it), and temperament\n",
      "- Your area in Mumbai\n",
      "- Any training goals (e.g., better recall, loose-leash walking, basic commands)\n",
      "- How many days you can spare for short sessions\n",
      "\n",
      "Want me to draft a personalized plan for Max? If yes, share the details above.\n",
      "   Messages in history: 6\n",
      "\n",
      "7. You: What's my name?\n",
      "   Bot: Your name is Bipin.\n",
      "\n",
      "What would you like to do next—biryani recipe, Max’s training plan, or dog-friendly spots in Mumbai?\n",
      "   Messages in history: 6\n",
      "\n",
      "8. You: Where do I work?\n",
      "   Bot: I don't know where you work—your messages haven't mentioned it. If you share your workplace or area (e.g., a part of Mumbai), I can tailor suggestions for you, such as:\n",
      "- dog-friendly spots near your office\n",
      "- a Max training plan that fits around your work hours\n",
      "- a commute-friendly schedule for practice\n",
      "\n",
      "Would you like to share your workplace or area, and what you’d like help with?\n",
      "   Messages in history: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate a long conversation\n",
    "trim_config = {\"configurable\": {\"thread_id\": \"trim_test\"}}\n",
    "\n",
    "# Send multiple messages\n",
    "messages_to_send = [\n",
    "    \"Hi! My name is Bipin.\",\n",
    "    \"I live in Mumbai.\",\n",
    "    \"I work as a software engineer.\",\n",
    "    \"I love playing cricket.\",\n",
    "    \"My favorite food is biryani.\",\n",
    "    \"I have a dog named Max.\",\n",
    "    \"What's my name?\",  # This should still work\n",
    "    \"Where do I work?\",  # This might be forgotten due to trimming\n",
    "]\n",
    "\n",
    "print(\"Sending messages to agent with trimming...\\n\")\n",
    "\n",
    "for i, user_msg in enumerate(messages_to_send, 1):\n",
    "    response = agent_with_trimming.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_msg}]},\n",
    "        trim_config\n",
    "    )\n",
    "    bot_response = response[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"{i}. You: {user_msg}\")\n",
    "    print(f\"   Bot: {bot_response}\")\n",
    "    print(f\"   Messages in history: {len(response['messages'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21330526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdf027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e45fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e982e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bipin.', additional_kwargs={}, response_metadata={}, id='3ac2fa1f-710b-48d1-a3eb-a490e3da2218'),\n",
       "  AIMessage(content='Nice! Max sounds like a champ. Here are a few ways I can help with Max and your cricket routine:\\n\\n- Quick dog-care checklist\\n  - Vaccinations, microchip, flea/tick prevention, regular grooming\\n  - Feeding amounts by weight, water hygiene, and a simple weekly weight check\\n  - Safe chew toys and crate/space for downtime\\n\\n- Training and enrichment for Max\\n  - Basic commands: sit, stay, recall, leash manners\\n  - Fun activities: fetch, scent games, short agility-style drills in a park or backyard\\n  - 5–10 minute mini-sessions you can slot between nets or practice days\\n\\n- Fitness-friendly ideas for you both\\n  - Short warm-ups with Max before or after cricket practice (e.g., a brisk 5-minute walk, a few quick sprints with a leash, some recall work)\\n  - Gentle play sessions to burn energy on rest days (tug, fetch, puzzle toys)\\n\\n- Local spot help in Mumbai\\n  - I can find dog-friendly parks, walking routes, and dog-friendly constellations near you—tell me your area and preferred activities.\\n\\nIf you’d like, I can tailor a simple 2–4 week plan for Max (training goals, weekly schedule, and quick at-home drills). A few quick details will help:\\n- Max’s age, breed (if you know it), and temperament\\n- Your area in Mumbai\\n- Any training goals (e.g., better recall, loose-leash walking, basic commands)\\n- How many days you can spare for short sessions\\n\\nWant me to draft a personalized plan for Max? If yes, share the details above.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1374, 'prompt_tokens': 984, 'total_tokens': 2358, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxBWmZ9iNUAt18n3Le5EpmXLdeS0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f17-4ad7-7ed2-b575-aed504c6f35c-0', usage_metadata={'input_tokens': 984, 'output_tokens': 1374, 'total_tokens': 2358, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a74168c4-a02f-4d3f-aca7-11c1b84b0b08'),\n",
       "  AIMessage(content='Your name is Bipin.\\n\\nWhat would you like to do next—biryani recipe, Max’s training plan, or dog-friendly spots in Mumbai?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 360, 'prompt_tokens': 965, 'total_tokens': 1325, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxBqW0xIF4dDg17REgNtzTNymPMq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f17-980c-7541-a4f1-091a0d4e7238-0', usage_metadata={'input_tokens': 965, 'output_tokens': 360, 'total_tokens': 1325, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}),\n",
       "  HumanMessage(content='Where do I work?', additional_kwargs={}, response_metadata={}, id='37397674-dadc-4005-9432-01cc39ab7133'),\n",
       "  AIMessage(content=\"I don't know where you work—your messages haven't mentioned it. If you share your workplace or area (e.g., a part of Mumbai), I can tailor suggestions for you, such as:\\n- dog-friendly spots near your office\\n- a Max training plan that fits around your work hours\\n- a commute-friendly schedule for practice\\n\\nWould you like to share your workplace or area, and what you’d like help with?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 478, 'prompt_tokens': 415, 'total_tokens': 893, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxBwkcmRneq2NpKhurjsd5CjbJwX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f17-ac6d-7023-87ef-71255b228a09-0', usage_metadata={'input_tokens': 415, 'output_tokens': 478, 'total_tokens': 893, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af2ead",
   "metadata": {},
   "source": [
    "### Key Observations with Trimming\n",
    "\n",
    "- The agent remembers your name (recent messages)\n",
    "- But it might forget earlier details like where you work (trimmed messages)\n",
    "- The message count stays bounded (doesn't grow indefinitely)\n",
    "- **Cost savings**: Only recent messages are sent to the LLM each time\n",
    "\n",
    "### Pros and Cons of Trimming\n",
    "\n",
    "**Pros:**\n",
    "- Fast and simple\n",
    "- Guaranteed cost savings\n",
    "- No extra LLM calls needed\n",
    "\n",
    "**Cons:**\n",
    "- Loses information from trimmed messages\n",
    "- May forget important context from earlier in the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a629c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422ef0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac6d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf12a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24ed564",
   "metadata": {},
   "source": [
    "\n",
    "## Approach 2: Message Summarization (Intelligent Compression)\n",
    "\n",
    "Instead of deleting old messages, we can **summarize** them! This preserves important context while reducing token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ebcad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent with summarization middleware created!\n"
     ]
    }
   ],
   "source": [
    "# Import summarization middleware\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "# Create an agent with automatic summarization\n",
    "summary_memory = MemorySaver()\n",
    "\n",
    "agent_with_summarization = create_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=llm,\n",
    "            trigger=(\"tokens\", 500),\n",
    "            keep=(\"messages\", 4),\n",
    "        ),\n",
    "    ],\n",
    "    checkpointer=summary_memory\n",
    ")\n",
    "\n",
    "print(\"Agent with summarization middleware created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d801776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending messages to agent with summarization...\n",
      "\n",
      "1. You: Hi! My name is Bipin.\n",
      "   Bot: Hi Bipin! Nice to meet you. How can I help today? \n",
      "\n",
      "You can ask me to explain a topic, solve a problem, draft or edit something (emails, essays, resum...\n",
      "\n",
      "2. You: I live in Mumbai.\n",
      "   Bot: Nice to meet you, Bipin! Cool to know you’re in Mumbai—that’s a vibrant place with lots of possibilities. I can tailor help to your location. What wou...\n",
      "\n",
      "3. You: I work as a software engineer.\n",
      "   Bot: Nice to meet you again, Bipin. Since you’re a software engineer in Mumbai, I can help with resume/LinkedIn optimization for local roles, interview pre...\n",
      "\n",
      "4. You: I love playing cricket.\n",
      "   Bot: Awesome! Cricket is such a Mumbai-thing. I can help you weave it nicely with your software career. Here are a few options you might want:\n",
      "\n",
      "- Find loca...\n",
      "\n",
      "5. You: My favorite food is biryani.\n",
      "   Bot: Nice pair of favorites! Biryani and cricket fit nicely into a Mumbai-based software career story. Here are a few ready-to-use snippets you can drop in...\n",
      "\n",
      "6. You: I have a dog named Max.\n",
      "   Bot: Nice! Max the dog can be a great personal touch. Here are some ready-to-use snippets you can drop into LinkedIn, your resume, or an interview intro. P...\n",
      "\n",
      "7. You: I also enjoy reading science fiction books.\n",
      "   Bot: Nice additions. Here are updated ready-to-use snippets that include science fiction reading, along with Max, cricket, and biryani. You can drop these ...\n",
      "\n",
      "8. You: My favorite author is Isaac Asimov.\n",
      "   Bot: Awesome detail. Here are updated ready-to-use snippets that weave in Isaac Asimov as your favorite author, along with Max, cricket, and science fictio...\n",
      "\n",
      "9. You: What's my name?\n",
      "   Bot: Bipin. If you’d like, share your last name and I’ll tailor headers/resume lines to use your full name (e.g., Bipin [LastName]) for a more formal profi...\n",
      "\n",
      "10. You: What do you know about me?\n",
      "   Bot: Here’s what I know about you from our chat:\n",
      "\n",
      "- Name: Bipin (you can share your last name if you want formal headers like Bipin [LastName]).\n",
      "- Location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test summarization with a long conversation\n",
    "summary_config = {\"configurable\": {\"thread_id\": \"summary_test\"}}\n",
    "\n",
    "# Same messages as before\n",
    "messages_to_send = [\n",
    "    \"Hi! My name is Bipin.\",\n",
    "    \"I live in Mumbai.\",\n",
    "    \"I work as a software engineer.\",\n",
    "    \"I love playing cricket.\",\n",
    "    \"My favorite food is biryani.\",\n",
    "    \"I have a dog named Max.\",\n",
    "    \"I also enjoy reading science fiction books.\",\n",
    "    \"My favorite author is Isaac Asimov.\",\n",
    "    \"What's my name?\",\n",
    "    \"What do you know about me?\",  # This should include summarized info!\n",
    "]\n",
    "\n",
    "print(\"Sending messages to agent with summarization...\\n\")\n",
    "\n",
    "for i, user_msg in enumerate(messages_to_send, 1):\n",
    "    response = agent_with_summarization.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_msg}]},\n",
    "        summary_config\n",
    "    )\n",
    "    bot_response = response[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"{i}. You: {user_msg}\")\n",
    "    print(f\"   Bot: {bot_response[:150]}...\")  # Truncate for readability\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de2d9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n- Bipin, Mumbai-based software engineer.\\n\\n- Goals: career guidance for the Mumbai market; resume and LinkedIn optimization for local roles; interview preparation; upskilling/learning plan; overall career strategy; salary benchmarks; networking plan.\\n\\n- Requests: resume/LinkedIn review; mock interview; stack-specific learning plan; networking plan; salary benchmarks.\\n\\n- Personal branding elements: Max the dog; cricket; reading science fiction.\\n\\n- Current science fiction detail: favorite author Isaac Asimov.\\n\\n- Tailoring preferences: customize to stack and years of experience; target Mumbai roles/companies; tone preference (formal vs casual).\\n\\n- Immediate next step: draft a full-stack–specific resume and LinkedIn version that mentions Max; need stack and years of experience to tailor.', additional_kwargs={}, response_metadata={}, id='59c521a1-7008-413c-a5b0-262c4543b67d'),\n",
       "  AIMessage(content='Awesome detail. Here are updated ready-to-use snippets that weave in Isaac Asimov as your favorite author, along with Max, cricket, and science fiction. Drop these into LinkedIn, your resume, or an interview intro. If you share your exact stack and years of experience, I’ll tailor a full stack-specific version.\\n\\n1) LinkedIn About (professional tone with a personal touch)\\nSoftware engineer in Mumbai with X years of experience delivering scalable, reliable software. I value teamwork, craftsmanship, and continuous learning—principles I strengthen through cricket, Isaac Asimov\\'s science fiction, and time with my dog Max. I’m excited by future-facing tech and open to Mumbai-based backend/full-stack roles.\\n\\n2) Elevator pitch (friendly and concise)\\nHi, I’m Bipin, a Mumbai-based software engineer focused on building reliable systems. Off the clock, I love cricket, Isaac Asimov\\'s science fiction, and I’m a proud dog dad to Max. I’m looking to join a team that values craft, collaboration, and growth with a forward-looking mindset.\\n\\n3) Resume/Interests section\\nInterests: Cricket, biryani, Isaac Asimov\\'s science fiction, and dog ownership (Max), plus active participation in Mumbai’s tech and local communities.\\n\\n4) Quick networking intro (DM or email opening)\\nHi [Name], I’m Bipin, a software engineer in Mumbai. I share a passion for cricket, Isaac Asimov\\'s science fiction, and I have a dog named Max. I’d love to learn more about your work at [Company] and explore how my background in [stack/role] could fit your team.\\n\\n5) Interview talking point (how you frame a strength)\\nWhen I design systems, I think about scalability and future needs—habits reinforced by reading Isaac Asimov\\'s science fiction, which helps me imagine multiple future scenarios and plan accordingly. In my spare time I also coach cricket and spend time with Max. I also consider ethical/safe automation insights inspired by Asimov’s ideas to inform design decisions.\\n\\n6) Stack-tailored starter (fill in the stack)\\n- For Java/Spring back-end:\\n  \"Software engineer with X years specializing in backend systems using Java/Spring, microservices, and relational databases. I’m motivated by building scalable, maintainable services. Outside work: cricket, Isaac Asimov\\'s science fiction, and time with Max. Seeking Mumbai-based backend roles in [industry/domain].\"\\n\\n- For Node.js/React (full-stack):\\n  \"Full-stack engineer with X years, focusing on Node.js/Express and React. I love delivering end-to-end features with solid performance and clean UX. Outside work: cricket, Isaac Asimov\\'s science fiction, and my dog Max. Targeting Mumbai-based roles in [industry/domain].\"\\n\\n- For Python/Django:\\n  \"Software engineer with X years in Python/Django, REST APIs, and data-driven apps. I value clean code, testing, and reliability. Off-hours: cricket, Isaac Asimov\\'s science fiction, and Max. Seeking Mumbai-based roles in backend/full-stack teams.\"\\n\\nHow you use these\\n- Pick the tone (professional, friendly, or a mix) and swap in your exact stack and years.\\n- Add target companies or domains (fintech, ecommerce, etc.) if you have specifics.\\n- Use the Asimov angle to illustrate future-thinking, safety, and ethics in design.\\n\\nWant me to draft a full stack-specific version (resume + LinkedIn) that explicitly includes Max and Isaac Asimov, tailored to your exact stack and years of experience? If you share:\\n- tech stack and years of experience\\n- target roles or companies in Mumbai\\n- preferred tone (formal or casual)\\nI’ll tailor a complete stack-specific version.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1998, 'prompt_tokens': 1229, 'total_tokens': 3227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1216, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxLaoOlfrdOKSsHXSBEFVopExZAD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f20-cfd8-71b3-9156-7ade66b1c7b2-0', usage_metadata={'input_tokens': 1229, 'output_tokens': 1998, 'total_tokens': 3227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1216}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='cc5fb704-bc7b-4490-afa0-e33660593ce0'),\n",
       "  AIMessage(content='Bipin. If you’d like, share your last name and I’ll tailor headers/resume lines to use your full name (e.g., Bipin [LastName]) for a more formal profile.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 435, 'prompt_tokens': 1674, 'total_tokens': 2109, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxM1Hp2qkcQnpScxLFRQu6MI7lLU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f21-39c1-7c32-868e-2e12df1ec82d-0', usage_metadata={'input_tokens': 1674, 'output_tokens': 435, 'total_tokens': 2109, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}}),\n",
       "  HumanMessage(content='What do you know about me?', additional_kwargs={}, response_metadata={}, id='f6900e43-e39c-4565-b6a3-887c35f57fca'),\n",
       "  AIMessage(content='Here’s what I know about you from our chat:\\n\\n- Name: Bipin (you can share your last name if you want formal headers like Bipin [LastName]).\\n- Location: Mumbai, India.\\n- Occupation: Software engineer.\\n- Goals: \\n  - Career guidance tailored to the Mumbai market\\n  - Resume and LinkedIn optimization for local roles\\n  - Interview preparation\\n  - Upskilling/learning plan\\n  - Overall career strategy\\n  - Salary benchmarks\\n  - Networking plan\\n- Personal branding you want woven in:\\n  - Max the dog\\n  - Cricket\\n  - Reading science fiction\\n- Favorite author: Isaac Asimov\\n- Tailoring preferences: customize to stack and years of experience; target Mumbai roles/companies; tone preference (formal vs casual)\\n- Immediate next step you requested: a full-stack–specific resume and LinkedIn version that mentions Max; need stack and years of experience to tailor\\n\\nWhat I still need from you to tailor the resume/LinkedIn precisely:\\n- Your exact tech stack (e.g., Java/Spring, Node.js/React, Python/Django, etc.)\\n- Years of experience (and any notable segments, e.g., 2–4 years backend, 1 year frontend, etc.)\\n- Target roles or companies in Mumbai (or the domain you’re aiming for)\\n- Preferred tone: formal, neutral, or casual\\n- Whether you want to include your last name in headers/resume\\n\\nIf you share those, I’ll draft a complete stack-specific resume and LinkedIn version that includes Max and your Asimov-inspired framing.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1041, 'prompt_tokens': 1016, 'total_tokens': 2057, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnxMAdYA9we8rbM1IPDHD8ETLa4mN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2f21-5ad6-7740-a12c-598302055250-0', usage_metadata={'input_tokens': 1016, 'output_tokens': 1041, 'total_tokens': 2057, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae54512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88626fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67ab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31b9f53d",
   "metadata": {},
   "source": [
    "### How Summarization Works\n",
    "\n",
    "When the token count exceeds the threshold (500 tokens):\n",
    "\n",
    "1. The middleware takes old messages (except the last 4)\n",
    "2. Sends them to a cheaper model (gpt-4o-mini) with a prompt: \"Summarize this conversation\"\n",
    "3. Replaces the old messages with a single summary message\n",
    "4. Keeps recent messages intact for immediate context\n",
    "\n",
    "**Result:** The agent remembers details from the beginning of the conversation (via summary) AND recent context!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e8f6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing the Three Approaches\n",
    "\n",
    "| Approach | Memory | Cost Efficiency | Context Retention | Best For |\n",
    "|----------|--------|----------------|-------------------|----------|\n",
    "| **No Management** | Unlimited growth | Poor (grows linearly) | Perfect | Short conversations |\n",
    "| **Trimming** | Recent messages only | Excellent | Limited | Cost-sensitive, recent context matters |\n",
    "| **Summarization** | Summary + recent | Good | Excellent | Long conversations, full context needed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc78131",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
